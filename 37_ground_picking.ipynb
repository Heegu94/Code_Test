{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "anticipated-compensation",
   "metadata": {},
   "source": [
    "# [땅따먹기]\n",
    "___\n",
    "\n",
    "### [문제 설명]\n",
    "\n",
    "- 땅따먹기 게임을 하려고 합니다. 땅따먹기 게임의 땅(land)은 총 N행 4열로 이루어져 있고, 모든 칸에는 점수가 쓰여 있습니다. \n",
    "- 1행부터 땅을 밟으며 한 행씩 내려올 때, 각 행의 4칸 중 한 칸만 밟으면서 내려와야 합니다. \n",
    "- 단, 땅따먹기 게임에는 한 행씩 내려올 때, 같은 열을 연속해서 밟을 수 없는 특수 규칙이 있습니다.\n",
    "\n",
    "#### - 예를 들면,\n",
    "\n",
    "- | 1 | 2 | 3 | 5 |\n",
    "\n",
    "- | 5 | 6 | 7 | 8 |\n",
    "\n",
    "- | 4 | 3 | 2 | 1 |\n",
    "\n",
    "- 로 땅이 주어졌다면, 1행에서 네번째 칸 (5)를 밟았으면, 2행의 네번째 칸 (8)은 밟을 수 없습니다.\n",
    "\n",
    "- 마지막 행까지 모두 내려왔을 때, 얻을 수 있는 점수의 최대값을 return하는 solution 함수를 완성해 주세요. \n",
    "- 위 예의 경우, 1행의 네번째 칸 (5), 2행의 세번째 칸 (7), 3행의 첫번째 칸 (4) 땅을 밟아 16점이 최고점이 되므로 16을 return 하면 됩니다.\n",
    "\n",
    "___\n",
    "\n",
    "### [제한 사항]\n",
    "\n",
    "- 행의 개수 N : 100,000 이하의 자연수\n",
    "- 열의 개수는 4개이고, 땅(land)은 2차원 배열로 주어집니다.\n",
    "- 점수 : 100 이하의 자연수\n",
    "\n",
    "___\n",
    "\n",
    "### [입출력 예]\n",
    "\n",
    "![figure](C:/Users/ryank/Desktop/ryan/Code_Test/figure/37-1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-concept",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### [내 풀이]\n",
    "\n",
    "- iteration을 배열의 두번째 행부터 시작하여, 들어온 수의 순서가 포함되지 않는 순서를 이전 행에서 가장 큰 값으로 하나씩 더해준다. \n",
    "- 이를 반복하여, 마지막 배열의 가장 큰수를 return 하면 문제를 풀수 있을 거라 생각하고 접근하였다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "sustained-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "land = [[1,2,3,5],[5,6,7,8],[4,3,2,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "departmental-pollution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 5], [5, 6, 7, 8], [4, 3, 2, 1]]\n",
      "10\n",
      "[[1, 2, 3, 5], [10, 6, 7, 8], [4, 3, 2, 1]]\n",
      "11\n",
      "[[1, 2, 3, 5], [10, 11, 7, 8], [4, 3, 2, 1]]\n",
      "12\n",
      "[[1, 2, 3, 5], [10, 11, 12, 8], [4, 3, 2, 1]]\n",
      "11\n",
      "-=---\n",
      "[[1, 2, 3, 5], [10, 11, 12, 11], [4, 3, 2, 1]]\n",
      "16\n",
      "[[1, 2, 3, 5], [10, 11, 12, 11], [16, 3, 2, 1]]\n",
      "15\n",
      "[[1, 2, 3, 5], [10, 11, 12, 11], [16, 15, 2, 1]]\n",
      "13\n",
      "[[1, 2, 3, 5], [10, 11, 12, 11], [16, 15, 13, 1]]\n",
      "13\n",
      "-=---\n",
      "[[1, 2, 3, 5], [10, 11, 12, 11], [16, 15, 13, 13]]\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,len(land)):\n",
    "    for j in range(len(land[0])):\n",
    "        print(land)\n",
    "        land[i][j] += max(land[i-1][:j]+ land[i-1][j+1:])  \n",
    "        print(land[i][j])\n",
    "    print(\"-=---\")\n",
    "print(land)\n",
    "print(max(land[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "induced-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_picking(land):\n",
    "    for i in range(1,len(land)):\n",
    "        for j in range(len(land[0])):\n",
    "            land[i][j] += max(land[i-1][:j]+ land[i-1][j+1:])\n",
    "    return max(land[-1])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "enabling-indonesia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3018"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_picking([[3, 5, 6, 8], [3, 5, 3, 4], [5, 10, 4, 3], [1, 3000, 2, 1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
